\chapter{Conclusion}\label{chapter:Conclusion}
This thesis has first systematically evaluated the 
accessibility of HTML/CSS code generated by state-of-the-art 
multimodal large language models (MLLMs) from UI screenshots.
While the models have shown impressive capabilities in 
the generation of syntactically valid code that closely 
mirrors the original UI image, they all reveal 
persistent accessibility violations. Through an empirical study and analysis across 
different models, prompting techniques, and datasets, 
this thesis identifies recurring WCAG 2.1
violations, demonstrates the limited impact of naive 
prompting, and shows how more advanced prompting techniques 
can reduce but not fully resolve the accessibility gap.\newline
These findings highlight a critical insight: improving visual 
and functional code fidelity does not necessarily lead to 
accessible code. Instead, accessibility must be elevated 
to a first-class objective in the design and evaluation 
of AI-driven UI development.
As MLLMs continue to evolve, the challenge and opportunity 
lie in integrating accessibility as a core principle into 
the models' architecture and training corpus.
By rethinking accessibility as a fundamental necessity,
and not just as a post-processing step, we can take a 
significant step towards a more inclusive and user-centered 
web.