\chapter{Related Work}\label{chapter:RelatedWork}

\section{Background}
Large Language Models (LLMs) and their performances in various domains are improving 
rapidly. Especially, in the domain of coding those models show promising results. 
It is therefore not surprising to see attempts to automate frontend code generation.

\section{Image-to-Code}
The focus of the first attempts in this area was to capture the image as precise as 
possible in order to translate it into Frontend Code. As \textit{pix2code}~\parencite{beltramelli2017pix2code} 
used a combination of CNN encoder with a LSTM decoder to translate screenshots into 
a frontend specific language. While it showed promising results for the possibility 
of end-to-end learning, it could not create standard HTML/CSS.\newline
Within the recent years, LLMs have improved a lot and new vision capabilities have been 
added to the models. Instead of further retraining models, researchers have 
explored the capabilities of different prompting structures. A prominent example is
\textit{DCGen}~\parencite{wan2024dcgen} where researchers have segmented screenshots 
into smaller, visual segments, let LLMs generate code for each segment and reassemble 
them them afterwards. This approach reduces the misplacement of components and shows
improvements in the visual similarity.\newline
Other related papers explored ways to improve prompting techniques (paper). They 
showed that advanced prompting techniques, such as few-shot, chain-of-thought and 
self-reflection can improve the performance without changing the models parameters.


\section{Web Accessibility}
Even though the web has become more accessible over the past years, almost every website 
does not fully comply with the Web Content Accessibility Guidelines 
(WCAG)~\parencite{wcag22}. According to the 2025 annual \textit{WebAIM}
accessibility report, an average of 51 errors per webpage has been 
found across one million webpages tested~\parencite{webaim2025million}.
Since accessibility compliance does not only improve the user
experience for people with disabilities, but also helps with 
\textit{Search Engine Optimization} (SEO), it is not surprising to see 
recent research in this area. First, \textcite{aljedaani2024chatgpt}
asked developers to let ChatGPT generate frontend code and observe 
the corresponding accessibility violations of the outputs. While they 
found out that 84\% of the webpages contained accessibility violations,
they also demonstrated the LLMs' capabilities to repair roughly 
70\% of its own mistakes. However, more complex issues remain. 
Similar results have been shown by \textcite{suh2025accessiblecode}.
Introducing a feedback-driven approach helped to further improve 
the WCAG compliance.\newline
While recent research shows promising results, there does not exist 
a comparable work in the area of Image-to-Code. Especially due 
to rising frontend code generation, it will be interesting to see 
how the WCAG compliance will influence the visual similarity.


\section{AI-enhanced GUI testing}
if necessary...
