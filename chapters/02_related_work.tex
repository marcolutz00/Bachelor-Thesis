\chapter{Related Work}\label{chapter:RelatedWork}

\section{Background}
Large Language Models (LLMs) and their performances in various domains are improving 
rapidly. Especially, in the domain of code generation those models show promising results. 
It is therefore not surprising to see attempts to automate the creation of 
webpages and frontend code.

\section{Image-to-Code}
The focus of the first attempts in this area was to capture the image as precise as 
possible in order to translate it into Frontend Code. For instance, \textit{pix2code}~\parencite{beltramelli2017pix2code} 
used a combination of CNN encoder with a LSTM decoder to translate screenshots into 
a frontend specific language. While it showed promising results for the possibility 
of end-to-end learning, it could not create standard HTML/CSS.\newline
Within the recent years, LLMs have improved a lot and new vision capabilities have been 
added to the models. Instead of further retraining models, researchers have 
explored the capabilities of different prompting structures and pre-processing steps. 
A prominent example is
\textit{DCGen}~\parencite{wan2024dcgen} where researchers have segmented screenshots 
into smaller, visual segments for the LLMs to generate code for each segment and reassemble 
them afterwards. This approach reduces the misplacement of components and shows
improvements in the visual similarity.\newline
Other related papers explored ways to improve prompting techniques (paper). They 
showed that advanced prompting techniques, such as few-shot, chain-of-thought and 
self-reflection can improve the performance without changing the models parameters.


\section{Web Accessibility}
Even though the web has become more accessible over the past years, almost every website 
does not fully comply with the Web Content Accessibility Guidelines 
(WCAG)~\parencite{wcag21}. According to the 2025 annual \textit{WebAIM}
accessibility report, an average of 51 errors per webpage has been (noch aufnehmen, dass 96\% verstöße) 
found across one million webpages tested~\parencite{webaim2025million}.
In order to tackle this issue, recent research has inspected this topic.
First, \textcite{aljedaani2024chatgpt}
asked developers to let ChatGPT generate frontend code and observe 
the corresponding accessibility violations of the outputs. While they 
found out that 84\% of the webpages contained accessibility violations,
they also demonstrated the LLMs' capabilities to repair roughly 
70\% of its own mistakes. However, more complex issues remain. 
Similar results have been shown by \textcite{suh2025accessiblecode}.
Introducing a feedback-driven approach helped to further improve 
the WCAG compliance.\newline
While recent research shows promising results, there does not exist 
a comparable work in the area of Image-to-Code. 


\section{AI-enhanced GUI testing}
if necessary...
